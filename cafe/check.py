# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ì¹´í˜ ëª©ë¡ ì¤‘ë³µ í™•ì¸ ë„êµ¬
- store_nameê³¼ store_url_naver ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬
"""

from openpyxl import load_workbook
from collections import defaultdict

FILE_PATH = r"C:\Users\changjin\workspace\lab\pln\cafe\naver_cafe_list.xlsx"

def check_duplicates():
    print("ğŸ” ì¤‘ë³µ í™•ì¸ ì‹œì‘...\n")
    
    try:
        wb = load_workbook(FILE_PATH)
        ws = wb.active
        
        # ë°ì´í„° ì½ê¸° (í—¤ë” ì œì™¸)
        rows = list(ws.iter_rows(min_row=2, values_only=True))
        total_count = len(rows)
        
        print(f"ğŸ“Š ì´ {total_count}ê°œ í•­ëª© ë°œê²¬\n")
        
        # ì¤‘ë³µ ì²´í¬ìš© ë”•ì…”ë„ˆë¦¬
        name_dict = defaultdict(list)  # store_name -> [row_numbers]
        url_dict = defaultdict(list)   # store_url_naver -> [row_numbers]
        
        # ë°ì´í„° ìˆ˜ì§‘
        for idx, row in enumerate(rows, start=2):  # ì—‘ì…€ í–‰ ë²ˆí˜¸ëŠ” 2ë¶€í„° ì‹œì‘
            no, store_name, store_url_naver = row
            
            if store_name:
                name_dict[store_name].append((idx, no, store_url_naver))
            
            if store_url_naver:
                url_dict[store_url_naver].append((idx, no, store_name))
        
        # ì¤‘ë³µ ë¶„ì„
        name_duplicates = {k: v for k, v in name_dict.items() if len(v) > 1}
        url_duplicates = {k: v for k, v in url_dict.items() if len(v) > 1}
        
        # ê²°ê³¼ ì¶œë ¥
        print("="*70)
        print("ğŸ“ store_name ê¸°ì¤€ ì¤‘ë³µ")
        print("="*70)
        
        if name_duplicates:
            print(f"âš ï¸ {len(name_duplicates)}ê°œì˜ ì¤‘ë³µëœ ì´ë¦„ ë°œê²¬!\n")
            for name, occurrences in sorted(name_duplicates.items()):
                print(f"ğŸ”´ ì´ë¦„: {name}")
                print(f"   ì¤‘ë³µ íšŸìˆ˜: {len(occurrences)}íšŒ")
                for row_num, no, url in occurrences:
                    print(f"   - í–‰ {row_num} (no={no}): {url}")
                print()
        else:
            print("âœ… store_name ì¤‘ë³µ ì—†ìŒ!\n")
        
        print("="*70)
        print("ğŸ”— store_url_naver ê¸°ì¤€ ì¤‘ë³µ")
        print("="*70)
        
        if url_duplicates:
            print(f"âš ï¸ {len(url_duplicates)}ê°œì˜ ì¤‘ë³µëœ URL ë°œê²¬!\n")
            for url, occurrences in sorted(url_duplicates.items()):
                print(f"ğŸ”´ URL: {url}")
                print(f"   ì¤‘ë³µ íšŸìˆ˜: {len(occurrences)}íšŒ")
                for row_num, no, name in occurrences:
                    print(f"   - í–‰ {row_num} (no={no}): {name}")
                print()
        else:
            print("âœ… store_url_naver ì¤‘ë³µ ì—†ìŒ!\n")
        
        # ìš”ì•½
        print("="*70)
        print("ğŸ“ˆ ìš”ì•½")
        print("="*70)
        print(f"ì´ í•­ëª© ìˆ˜: {total_count}ê°œ")
        print(f"ì¤‘ë³µëœ ì´ë¦„: {len(name_duplicates)}ê°œ")
        print(f"ì¤‘ë³µëœ URL: {len(url_duplicates)}ê°œ")
        
        # ì¤‘ë³µ ì œê±° ì‹œ ë‚¨ì„ í•­ëª© ìˆ˜
        unique_urls = len(url_dict)
        print(f"URL ê¸°ì¤€ ê³ ìœ  í•­ëª©: {unique_urls}ê°œ")
        print(f"ì¤‘ë³µ ì œê±° ì‹œ ì‚­ì œë  í•­ëª©: {total_count - unique_urls}ê°œ")
        print("="*70)
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {FILE_PATH}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    check_duplicates()