import os
import json
import pandas as pd
import numpy as np
from haversine import haversine, Unit
import logging
from datetime import datetime, timedelta

# ========================================
# ì„¤ì •
# ========================================
CONFIG = {
    "USER_INFO_FILE": r"C:\Users\changjin\workspace\lab\pln\data_set\1000_user_info.csv",
    "USER_PREF_DIR": r"C:\Users\changjin\workspace\lab\pln\vector_embedding\review_count_with_softmax\for_clustering_user",
    "PLACE_FILE": r"C:\Users\changjin\workspace\lab\pln\data_set\last_clustering_category_combine_with_hours_and_price.csv",
    "OUTPUT_DIR": r"C:\Users\changjin\workspace\lab\pln\clustering_user\user_based_clusters_greedy",
    "LOG_DIR": r"C:\Users\changjin\workspace\lab\pln\clustering_user\logs",
    "PLACES_PER_CATEGORY": 15,  # ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœëŒ€ ì¥ì†Œ ìˆ˜
    "MAX_CLUSTER_RADIUS_KM": 6,  # í´ëŸ¬ìŠ¤í„° ìµœëŒ€ ë°˜ê²½
    "MIN_PLACES_PER_CATEGORY": 7,  # Seed ê²€ì¦: ê° ì¹´í…Œê³ ë¦¬ë³„ ìµœì†Œ ì¥ì†Œ ìˆ˜
}

# Accommodation ì œì™¸: Cafe, Restaurant, Attractionë§Œ ì‚¬ìš©
CLUSTER_CATEGORIES = ['Cafe', 'Restaurant', 'Attraction']

# ìš”ì¼ ë§¤í•‘ (í•œê¸€ â†’ ì˜ì–´)
WEEKDAY_MAP = {
    'ì¼': 'Sunday',
    'ì›”': 'Monday', 
    'í™”': 'Tuesday',
    'ìˆ˜': 'Wednesday',
    'ëª©': 'Thursday',
    'ê¸ˆ': 'Friday',
    'í† ': 'Saturday'
}

WEEKDAY_ENG_TO_KOR = {v: k for k, v in WEEKDAY_MAP.items()}

# í”¼í¬ ì‹œì¦Œ ì›”
PEAK_MONTHS = [7, 8, 12, 1]  # 7ì›”, 8ì›”, 12ì›”, 1ì›”

# ì£¼ë§ ìš”ì¼ (í•œê¸€)
WEEKEND_DAYS = ['ê¸ˆ', 'í† ']  # ê¸ˆìš”ì¼, í† ìš”ì¼

# ë¡œê¹… ì„¤ì •
logger = None

def setup_logging(log_dir):
    """ë¡œê¹… ì„¤ì •"""
    os.makedirs(log_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"clustering_{timestamp}.log")
    
    global logger
    logger = logging.getLogger('clustering')
    logger.setLevel(logging.INFO)
    logger.handlers.clear()
    
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)
    file_formatter = logging.Formatter('%(message)s')
    file_handler.setFormatter(file_formatter)
    
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter('%(message)s')
    console_handler.setFormatter(console_formatter)
    
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return log_file


def log_print(message):
    """ì½˜ì†”ê³¼ ë¡œê·¸ íŒŒì¼ ëª¨ë‘ì— ì¶œë ¥"""
    if logger:
        logger.info(message)
    else:
        print(message)


def get_weekday_from_date(date_str):
    """
    ë‚ ì§œ ë¬¸ìì—´ì—ì„œ ìš”ì¼ ì¶”ì¶œ
    Args:
        date_str: '2025-08-16' í˜•ì‹
    Returns:
        ìš”ì¼ í•œê¸€ (ì˜ˆ: 'í† ')
    """
    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
    weekday_eng = date_obj.strftime('%A')  # 'Saturday'
    return WEEKDAY_ENG_TO_KOR.get(weekday_eng, 'ì›”')


def is_peak_season(date_str):
    """
    í”¼í¬ ì‹œì¦Œ ì—¬ë¶€ íŒë‹¨
    Args:
        date_str: '2025-08-16' í˜•ì‹
    Returns:
        bool: 7ì›”, 8ì›”, 12ì›”, 1ì›”ì´ë©´ True
    """
    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
    return date_obj.month in PEAK_MONTHS


def is_weekend(weekday_kor):
    """
    ì£¼ë§ ì—¬ë¶€ íŒë‹¨
    Args:
        weekday_kor: í•œê¸€ ìš”ì¼ (ì˜ˆ: 'í† ')
    Returns:
        bool: ê¸ˆìš”ì¼, í† ìš”ì¼ì´ë©´ True
    """
    return weekday_kor in WEEKEND_DAYS


def parse_store_hours(store_hours_str):
    """
    ì˜ì—…ì‹œê°„ ë¬¸ìì—´ íŒŒì‹±
    Args:
        store_hours_str: 'ì¼: 10:30 - 20:00; ì›”: 10:30 - 20:00; í™”: íœ´ë¬´; ...'
    Returns:
        dict: {'ì¼': 'open', 'ì›”': 'open', 'í™”': 'closed', ...}
    """
    if pd.isna(store_hours_str) or store_hours_str.strip() == '':
        # ì˜ì—…ì‹œê°„ ì •ë³´ ì—†ìŒ â†’ ëª¨ë“  ìš”ì¼ ì˜ì—…ìœ¼ë¡œ ê°„ì£¼
        return {day: 'open' for day in WEEKDAY_MAP.keys()}
    
    hours_dict = {}
    
    # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬
    parts = store_hours_str.split(';')
    
    for part in parts:
        part = part.strip()
        if ':' not in part:
            continue
        
        # 'ì¼: 10:30 - 20:00' ë˜ëŠ” 'í™”: íœ´ë¬´'
        day, info = part.split(':', 1)
        day = day.strip()
        info = info.strip()
        
        if day in WEEKDAY_MAP.keys():
            if 'íœ´ë¬´' in info:
                hours_dict[day] = 'closed'
            else:
                hours_dict[day] = 'open'
    
    # ëª…ì‹œë˜ì§€ ì•Šì€ ìš”ì¼ì€ ì˜ì—…ìœ¼ë¡œ ê°„ì£¼
    for day in WEEKDAY_MAP.keys():
        if day not in hours_dict:
            hours_dict[day] = 'open'
    
    return hours_dict


def is_open_on_day(store_hours_str, target_day):
    """
    íŠ¹ì • ìš”ì¼ì— ì˜ì—…í•˜ëŠ”ì§€ í™•ì¸
    Args:
        store_hours_str: ì˜ì—…ì‹œê°„ ë¬¸ìì—´
        target_day: í™•ì¸í•  ìš”ì¼ (í•œê¸€, ì˜ˆ: 'í† ')
    Returns:
        bool: ì˜ì—… ì—¬ë¶€
    """
    hours_dict = parse_store_hours(store_hours_str)
    return hours_dict.get(target_day, 'open') == 'open'


def load_place_locations(place_file):
    """ì¥ì†Œ ìœ„ê²½ë„, ì˜ì—…ì‹œê°„, ê°€ê²© ì •ë³´ ë¡œë“œ"""
    df = pd.read_csv(place_file)
    location_dict = {}

    for _, row in df.iterrows():
        location_dict[row['id']] = {
            'latitude': row['latitude'],
            'longitude': row['longitude'],
            'name': row['name'],
            'category': row['category'],
            'store_hours': row.get('store_hours', ''),
            # ê°€ê²© ì •ë³´ ì¶”ê°€
            'offpeak_weekday_price_avg': row.get('offpeak_weekday_price_avg', None),
            'offpeak_weekend_price_avg': row.get('offpeak_weekend_price_avg', None),
            'peak_weekday_price_avg': row.get('peak_weekday_price_avg', None),
            'peak_weekend_price_avg': row.get('peak_weekend_price_avg', None),
        }

    return location_dict


def extract_all_user_places(user_pref_file, location_dict):
    """ìœ ì € ì„ í˜¸ë„ ì¥ì†Œ ì¶”ì¶œ (Accommodation ì œì™¸)"""
    with open(user_pref_file, 'r', encoding='utf-8') as f:
        preferences = json.load(f)
    
    user_places = []
    
    for category, places in preferences.items():
        # Accommodation ì œì™¸
        if category not in CLUSTER_CATEGORIES:
            continue
        
        for place in places:
            place_id = place['id']
            if place_id in location_dict:
                loc = location_dict[place_id]
                user_places.append({
                    'id': place_id,
                    'name': loc['name'],
                    'category': category,
                    'latitude': loc['latitude'],
                    'longitude': loc['longitude'],
                    'final_score': place['final_score'],
                    'store_hours': loc['store_hours']
                })
    
    return pd.DataFrame(user_places)


def validate_seed(seed_location, available_df, max_radius_km, min_places_per_category):
    """
    Seedê°€ ì í•©í•œì§€ ê²€ì¦: ì£¼ë³€ì— ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìµœì†Œ ê°œìˆ˜ ì´ìƒì˜ ì¥ì†Œê°€ ìˆëŠ”ì§€ í™•ì¸
    """
    category_counts = {}
    
    for category in CLUSTER_CATEGORIES:
        category_places = available_df[available_df['category'] == category].copy()
        
        if len(category_places) == 0:
            category_counts[category] = 0
            continue
        
        # Seedë¡œë¶€í„° ê±°ë¦¬ ê³„ì‚°
        category_places['distance'] = category_places.apply(
            lambda r: haversine(seed_location, 
                               (r['latitude'], r['longitude']),
                               unit=Unit.KILOMETERS),
            axis=1
        )
        
        # max_radius_km ì´ë‚´ì˜ ì¥ì†Œ ê°œìˆ˜
        count = len(category_places[category_places['distance'] <= max_radius_km])
        category_counts[category] = count
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ê°€ ìµœì†Œ ê°œìˆ˜ ì´ìƒì¸ì§€ í™•ì¸
    is_valid = all(count >= min_places_per_category for count in category_counts.values())
    
    return is_valid, category_counts


def find_nearest_places(seed_location, available_df, category, n_places, max_radius_km):
    """Seed ìœ„ì¹˜ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´ Nê°œì˜ ì¥ì†Œ ì°¾ê¸°"""
    category_places = available_df[available_df['category'] == category].copy()
    
    if len(category_places) == 0:
        return pd.DataFrame()
    
    # Seedë¡œë¶€í„° ê±°ë¦¬ ê³„ì‚°
    category_places['distance'] = category_places.apply(
        lambda r: haversine(seed_location, 
                           (r['latitude'], r['longitude']),
                           unit=Unit.KILOMETERS),
        axis=1
    )
    
    # max_radius_km ì´ë‚´ì˜ ì¥ì†Œë§Œ í•„í„°ë§
    category_places = category_places[category_places['distance'] <= max_radius_km]
    
    if len(category_places) == 0:
        return pd.DataFrame()
    
    # ê±°ë¦¬ ê°€ê¹Œìš´ ìˆœìœ¼ë¡œ ì •ë ¬
    category_places = category_places.sort_values('distance', ascending=True)
    
    return category_places.head(n_places)


def greedy_clustering(df, n_clusters, start_date, places_per_category, max_radius_km, min_places_per_category):
    """
    Greedy ë°©ì‹ í´ëŸ¬ìŠ¤í„°ë§ (Accommodation ì œì™¸, ì˜ì—…ì‹œê°„ ì²´í¬)
    """
    clusters = []
    cluster_centers = []
    used_place_ids = set()
    available_df = df.copy()
    
    # ì‹œì‘ ë‚ ì§œ datetime ê°ì²´ë¡œ ë³€í™˜
    start_date_obj = datetime.strptime(start_date, '%Y-%m-%d')
    
    for cluster_idx in range(n_clusters):
        # í•´ë‹¹ í´ëŸ¬ìŠ¤í„°ì˜ ë‚ ì§œ ê³„ì‚° (ì‹œì‘ì¼ + cluster_idxì¼)
        cluster_date = start_date_obj + timedelta(days=cluster_idx)
        cluster_date_str = cluster_date.strftime('%Y-%m-%d')
        cluster_weekday = get_weekday_from_date(cluster_date_str)
        
        log_print(f"\n{'='*70}")
        log_print(f"ğŸ“… Day {cluster_idx} - {cluster_date_str} ({cluster_weekday}ìš”ì¼)")
        log_print(f"{'='*70}")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ Seed í›„ë³´ í•„í„°ë§ (ì´ë¯¸ ì‚¬ìš©ëœ ì¥ì†Œ ì œì™¸)
        available_seeds = available_df[~available_df['id'].isin(used_place_ids)].copy()
        
        if len(available_seeds) == 0:
            log_print(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {cluster_idx}: ë” ì´ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ì—†ìŒ")
            break
        
        # ì˜ì—…ì‹œê°„ ì²´í¬: í•´ë‹¹ ë‚ ì§œì˜ ìš”ì¼ì— íœ´ë¬´ì¸ ì¥ì†Œ ì œì™¸
        available_seeds['is_open'] = available_seeds['store_hours'].apply(
            lambda x: is_open_on_day(x, cluster_weekday)
        )
        
        # íœ´ë¬´ì¸ ì¥ì†Œ ë¡œê·¸ ì¶œë ¥
        closed_places = available_seeds[~available_seeds['is_open']]
        if len(closed_places) > 0:
            log_print(f"   ğŸ“… {cluster_weekday}ìš”ì¼ íœ´ë¬´ë¡œ Seed í›„ë³´ì—ì„œ ì œì™¸: {len(closed_places)}ê°œ")
            for _, place in closed_places.head(10).iterrows():
                log_print(f"      - {place['name']} ({place['category']}, Score: {place['final_score']:.4f})")
        
        available_seeds = available_seeds[available_seeds['is_open']].copy()
        
        if len(available_seeds) == 0:
            log_print(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {cluster_idx}: {cluster_weekday}ìš”ì¼ì— ì˜ì—…í•˜ëŠ” ì¥ì†Œ ì—†ìŒ")
            log_print(f"   â†’ ì˜ì—…ì‹œê°„ ë¬´ì‹œí•˜ê³  ì§„í–‰")
            available_seeds = available_df[~available_df['id'].isin(used_place_ids)].copy()
        
        # ëª¨ë“  í´ëŸ¬ìŠ¤í„°ì—ì„œ final_score ìˆœìœ¼ë¡œ ì •ë ¬
        seed_candidates = available_seeds.sort_values('final_score', ascending=False)
        
        # ì í•©í•œ Seed ì°¾ê¸° (ê²€ì¦ í†µê³¼í•  ë•Œê¹Œì§€)
        seed_place = None
        seed_location = None
        
        for _, candidate in seed_candidates.iterrows():
            candidate_location = (candidate['latitude'], candidate['longitude'])
            
            # Seed ê²€ì¦
            is_valid, category_counts = validate_seed(
                candidate_location,
                available_df[~available_df['id'].isin(used_place_ids)],
                max_radius_km,
                min_places_per_category
            )
            
            if is_valid:
                seed_place = candidate
                seed_location = candidate_location
                log_print(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_idx} Seed ê²€ì¦ í†µê³¼: {candidate['name']} ({candidate['category']})")
                for cat, cnt in category_counts.items():
                    log_print(f"   {cat}: {cnt}ê°œ ì‚¬ìš© ê°€ëŠ¥")
                break
            else:
                failed_cats = [cat for cat, cnt in category_counts.items() if cnt < min_places_per_category]
                log_print(f"âŒ Seed í›„ë³´ '{candidate['name']}' ê²€ì¦ ì‹¤íŒ¨: {', '.join(failed_cats)} ë¶€ì¡±")
        
        if seed_place is None:
            log_print(f"âš ï¸ í´ëŸ¬ìŠ¤í„° {cluster_idx}: ê²€ì¦ì„ í†µê³¼í•œ Seedë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            seed_place = seed_candidates.iloc[0]
            seed_location = (seed_place['latitude'], seed_place['longitude'])
            log_print(f"âš ï¸ ê²€ì¦ ì—†ì´ ì§„í–‰: {seed_place['name']}")
        
        if len(cluster_centers) > 0:
            min_dist = min([haversine(seed_location, c, unit=Unit.KILOMETERS) for c in cluster_centers])
            log_print(f"ğŸ¯ í´ëŸ¬ìŠ¤í„° {cluster_idx} Seed: {seed_place['name']} ({seed_place['category']}, Score: {seed_place['final_score']:.4f}, ìµœê·¼ì ‘ í´ëŸ¬ìŠ¤í„°: {min_dist:.1f}km)")
        else:
            log_print(f"ğŸ¯ í´ëŸ¬ìŠ¤í„° {cluster_idx} Seed: {seed_place['name']} ({seed_place['category']}, Score: {seed_place['final_score']:.4f})")
        
        seed_category = seed_place['category']
        cluster_places = {seed_category: [seed_place]}
        used_place_ids.add(seed_place['id'])
        
        for category in CLUSTER_CATEGORIES:
            if category == seed_category:
                n_to_find = places_per_category - 1
            else:
                n_to_find = places_per_category
            
            if n_to_find <= 0:
                continue
            
            available_category = available_df[
                (available_df['category'] == category) &
                (~available_df['id'].isin(used_place_ids))
            ]
            
            nearest = find_nearest_places(
                seed_location,
                available_category,
                category,
                n_to_find,
                max_radius_km
            )
            
            if category not in cluster_places:
                cluster_places[category] = []
            
            for _, place in nearest.iterrows():
                cluster_places[category].append(place)
                used_place_ids.add(place['id'])
            
            if len(nearest) > 0:
                avg_dist = nearest['distance'].mean()
                max_dist = nearest['distance'].max()
                log_print(f"   {category}: {len(cluster_places[category])}ê°œ ì¶”ê°€ (í‰ê· : {avg_dist:.1f}km, ìµœëŒ€: {max_dist:.1f}km)")
            else:
                log_print(f"   {category}: 0ê°œ ì¶”ê°€ ({max_radius_km}km ì´ë‚´ ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì†Œ ì—†ìŒ)")
        
        center_lat = seed_location[0]
        center_lng = seed_location[1]
        cluster_centers.append((center_lat, center_lng))
        
        cluster_data = {
            'cluster_id': cluster_idx,
            'date': cluster_date_str,
            'weekday': cluster_weekday,
            'seed_category': seed_category,
            'seed_place': {
                'id': int(seed_place['id']),
                'name': seed_place['name'],
                'final_score': round(float(seed_place['final_score']), 4)
            },
            'center_lat': round(center_lat, 6),
            'center_lng': round(center_lng, 6),
            'categories': {}
        }
        
        for category in CLUSTER_CATEGORIES:
            places_list = []
            if category in cluster_places:
                for place in cluster_places[category]:
                    distance = haversine(
                        (center_lat, center_lng),
                        (place['latitude'], place['longitude']),
                        unit=Unit.KILOMETERS
                    )
                    places_list.append({
                        'id': int(place['id']),
                        'name': place['name'],
                        'final_score': round(float(place['final_score']), 4),
                        'distance_from_center': round(distance, 2)
                    })
            
            cluster_data['categories'][category] = places_list
        
        clusters.append(cluster_data)
        log_print(f"âœ… í´ëŸ¬ìŠ¤í„° {cluster_idx} ì™„ë£Œ: ì´ {len(used_place_ids)}ê°œ ì¥ì†Œ ì‚¬ìš©ë¨")
    
    return clusters


def select_best_accommodation(user_pref_file, clusters, location_dict, start_date, budget, duration_days, 
                              distance_weight=0.15, max_distance_km=10.0):
    """
    ì˜ˆì‚°ì„ ê³ ë ¤í•˜ì—¬ ìµœì ì˜ ìˆ™ì†Œ ì„ íƒ (30~50% í—ˆìš© ë²”ìœ„)
    """
    if len(clusters) == 0:
        return None
    
    coords = np.array([[c['center_lat'], c['center_lng']] for c in clusters])
    mean = coords.mean(axis=0)
    
    log_print(f"\n{'='*70}")
    log_print(f"ğŸ¨ ìˆ™ì†Œ ì„ íƒ ì¤‘...")
    log_print(f"{'='*70}")
    
    # =============================
    # 1ï¸âƒ£ ê°€ì¤‘ í‰ê·  ì¤‘ì‹¬ ê³„ì‚°
    # =============================
    dist = np.array([haversine((mean[0], mean[1]), (c['center_lat'], c['center_lng']), unit=Unit.KILOMETERS)
                     for c in clusters])
    weights = 1 / (1 + dist**2)
    weighted_center = np.average(coords, axis=0, weights=weights)
    overall_center_lat, overall_center_lng = weighted_center
    
    # =============================
    # 2ï¸âƒ£ ì˜ˆì‚° ê³„ì‚° (30~50%)
    # =============================
    accommodation_nights = duration_days - 1  # ìˆ™ë°• ì¼ìˆ˜
    min_accommodation_budget = budget * 0.3
    max_accommodation_budget = budget * 0.5
    per_night_min = min_accommodation_budget / accommodation_nights
    per_night_max = max_accommodation_budget / accommodation_nights
    
    log_print(f"\nğŸ’° ì˜ˆì‚° ë²”ìœ„:")
    log_print(f"   - ì „ì²´ ì˜ˆì‚°: {budget:,}ì›")
    log_print(f"   - ìˆ™ì†Œ ì´ ì˜ˆì‚° ë²”ìœ„: {min_accommodation_budget:,.0f}ì› ~ {max_accommodation_budget:,.0f}ì›")
    log_print(f"   - 1ë°•ë‹¹ ì˜ˆì‚° ë²”ìœ„: {per_night_min:,.0f}ì› ~ {per_night_max:,.0f}ì›")
    
    # =============================
    # 3ï¸âƒ£ ì‹œì¦Œ / ìš”ì¼ íŒë‹¨
    # =============================
    peak = is_peak_season(start_date)
    start_weekday = get_weekday_from_date(start_date)
    weekend = is_weekend(start_weekday)
    
    season = "peak" if peak else "offpeak"
    day_type = "weekend" if weekend else "weekday"
    price_column = f"{season}_{day_type}_price_avg"
    
    log_print(f"\nğŸ“… ì‹œì¦Œ/ìš”ì¼ ì •ë³´:")
    log_print(f"   - ì‹œì¦Œ: {season}")
    log_print(f"   - ìš”ì¼: {day_type}")
    log_print(f"   - ì ìš© ê°€ê²© ì»¬ëŸ¼: {price_column}")
    
    # =============================
    # 4ï¸âƒ£ í›„ë³´ í•„í„°ë§
    # =============================
    with open(user_pref_file, 'r', encoding='utf-8') as f:
        preferences = json.load(f)
    
    accommodations = preferences.get('Accommodation', [])
    if len(accommodations) == 0:
        log_print("âš ï¸ ìˆ™ì†Œ ì„ í˜¸ë„ ì •ë³´ ì—†ìŒ")
        return None
    
    scored_accommodations = []
    for acc in accommodations:
        acc_id = acc['id']
        if acc_id not in location_dict:
            continue
        
        acc_info = location_dict[acc_id]
        acc_lat, acc_lng = acc_info['latitude'], acc_info['longitude']
        acc_price = acc_info.get(price_column)
        
        # ìœ íš¨ ê°€ê²© í•„í„°: 30~50% ì˜ˆì‚° ë²”ìœ„ ë‚´
        if pd.isna(acc_price) or acc_price is None:
            continue
        if acc_price < per_night_min or acc_price > per_night_max:
            continue
        
        # ê±°ë¦¬ ê³„ì‚°
        distance = haversine((overall_center_lat, overall_center_lng), (acc_lat, acc_lng), unit=Unit.KILOMETERS)
        if distance > max_distance_km:
            continue
        
        # ì ìˆ˜ ê³„ì‚° (ì„ í˜¸ë„ 85% + ê±°ë¦¬ 15%)
        preference_score = acc['final_score']
        distance_score = max(0, 1 - (distance / max_distance_km))
        final_score = (1 - distance_weight) * preference_score + distance_weight * distance_score
        
        scored_accommodations.append({
            'id': acc_id,
            'name': acc_info['name'],
            'price': acc_price,
            'distance': distance,
            'final_score': final_score
        })
    
    if len(scored_accommodations) == 0:
        log_print(f"âš ï¸ 1ë°•ë‹¹ {per_night_min:,.0f}~{per_night_max:,.0f}ì› ë²”ìœ„ì— ë§ëŠ” ìˆ™ì†Œ ì—†ìŒ")
        return None
    
    # =============================
    # 5ï¸âƒ£ ìµœì¢… ì„ íƒ
    # =============================
    scored_accommodations.sort(key=lambda x: x['final_score'], reverse=True)
    best = scored_accommodations[0]
    
    log_print(f"\nâœ… ì„ íƒëœ ìˆ™ì†Œ: {best['name']}")
    log_print(f"   - ê°€ê²©: {best['price']:,.0f}ì›")
    log_print(f"   - ê±°ë¦¬: {best['distance']:.2f}km")
    log_print(f"   - ìµœì¢… ì ìˆ˜: {best['final_score']:.4f}")
    
    return best['id']


def process_user(user_id, user_info, user_pref_dir, location_dict, output_dir):
    """ë‹¨ì¼ ìœ ì € ì²˜ë¦¬"""
    user_pref_file = os.path.join(user_pref_dir, f"{user_id}_recommendations_softmax.json")
    
    if not os.path.exists(user_pref_file):
        log_print(f"âš ï¸ {user_id} íŒŒì¼ ì—†ìŒ")
        return
    
    duration_days = user_info['duration_days']
    start_date = user_info['start_date']
    budget = user_info['budget']
    
    start_weekday = get_weekday_from_date(start_date)
    
    log_print(f"\n{'='*70}")
    log_print(f"ğŸ‘¤ {user_id} ì²˜ë¦¬ ì¤‘...")
    log_print(f"{'='*70}")
    log_print(f"   ì—¬í–‰ ì¼ìˆ˜: {duration_days}ì¼")
    log_print(f"   ì‹œì‘ ë‚ ì§œ: {start_date} ({start_weekday}ìš”ì¼)")
    log_print(f"   ì˜ˆì‚°: {budget:,}ì›")
    
    df = extract_all_user_places(user_pref_file, location_dict)
    
    log_print(f"âœ… ì¶”ì¶œëœ ì¥ì†Œ: {len(df)}ê°œ")
    for cat in CLUSTER_CATEGORIES:
        count = len(df[df['category'] == cat])
        log_print(f"   {cat}: {count}ê°œ")
    
    n_clusters = duration_days
    clusters = greedy_clustering(
        df,
        n_clusters,
        start_date,
        places_per_category=CONFIG['PLACES_PER_CATEGORY'],
        max_radius_km=CONFIG['MAX_CLUSTER_RADIUS_KM'],
        min_places_per_category=CONFIG['MIN_PLACES_PER_CATEGORY']
    )
    
    log_print(f"\nâœ… Greedy í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {len(clusters)}ê°œ í´ëŸ¬ìŠ¤í„°")
    
    # ìˆ™ì†Œ ì„ íƒ (1ì¼ ì—¬í–‰ì´ë©´ ìŠ¤í‚µ)
    accommodation_id = None
    if duration_days > 1:
        accommodation_id = select_best_accommodation(
            user_pref_file,
            clusters,
            location_dict,
            start_date,
            budget,
            duration_days,
            distance_weight=0.15,
            max_distance_km=10.0
        )
    else:
        log_print(f"\nğŸ¨ 1ì¼ ì—¬í–‰ìœ¼ë¡œ ìˆ™ì†Œ ë¶ˆí•„ìš”")
    
    result = {
        'user_id': user_id,
        'start_date': start_date,
        'start_weekday': start_weekday,
        'duration_days': duration_days,
        'budget': budget,
        'num_clusters': len(clusters),
        'clustering_method': 'greedy_score_based_with_store_hours',
        'seed_strategy': 'highest_score_only',
        'max_cluster_radius_km': CONFIG['MAX_CLUSTER_RADIUS_KM'],
        'min_places_per_category': CONFIG['MIN_PLACES_PER_CATEGORY'],
        'places_per_category': CONFIG['PLACES_PER_CATEGORY'],
        'Accommodation': accommodation_id,
        'clusters': clusters
    }
    
    os.makedirs(output_dir, exist_ok=True)
    output_file = os.path.join(output_dir, f"{user_id}_daily_clusters.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    log_print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {output_file}")


def process_all_users():
    """ëª¨ë“  ìœ ì € ì¼ê´„ ì²˜ë¦¬"""
    log_file = setup_logging(CONFIG['LOG_DIR'])
    log_print(f"ğŸ“ ë¡œê·¸ íŒŒì¼: {log_file}\n")
    
    os.makedirs(CONFIG['OUTPUT_DIR'], exist_ok=True)
    
    log_print("ğŸ“‚ ì¥ì†Œ ìœ„ì¹˜ ì •ë³´ ë¡œë“œ ì¤‘...")
    location_dict = load_place_locations(CONFIG['PLACE_FILE'])
    log_print(f"âœ… {len(location_dict)}ê°œ ì¥ì†Œ ìœ„ì¹˜ ì •ë³´ ë¡œë“œ ì™„ë£Œ\n")
    
    user_df = pd.read_csv(CONFIG['USER_INFO_FILE'])
    
    for idx, user in user_df.iterrows():
        user_id = user['user_id']
        user_info = {
            'duration_days': user['duration_days'],
            'start_date': user['start_date'],
            'budget': user['budget']
        }
        
        process_user(user_id, user_info, CONFIG['USER_PREF_DIR'],
                     location_dict, CONFIG['OUTPUT_DIR'])
    
    log_print(f"\n{'='*70}")
    log_print(f"âœ¨ ì „ì²´ ìœ ì € ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(user_df)}ëª…")
    log_print(f"ğŸ“ ë¡œê·¸ ì €ì¥ ì™„ë£Œ: {log_file}")
    log_print(f"{'='*70}")


if __name__ == "__main__":
    process_all_users()