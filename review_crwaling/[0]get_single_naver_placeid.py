import re, time, os, urllib.parse
import pandas as pd
from openpyxl import load_workbook  # ì—‘ì…€ append ë°±ì—… ìš©ë„ [ì„¤ì¹˜ í•„ìš”: pip install openpyxl]
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ===== ê²½ë¡œ ë° ì„¤ì • =====
INPUT_PATH  = "ê°•ë¦‰ì‹œ_ì¼ë°˜ìŒì‹ì  í˜„í™©.csv"
OUTPUT_PATH = "naver_placeid_list"
NAME_COL    = "ì—…ì†Œëª…"

# ===== ìœ í‹¸ =====
def read_korean_csv(path: str) -> pd.DataFrame:
    for enc in ("utf-8-sig", "cp949", "ms949", "euc-kr"):
        try:
            return pd.read_csv(path, encoding=enc)
        except UnicodeDecodeError:
            continue
    return pd.read_csv(path, encoding="utf-8", errors="ignore")  # [9]

def build_review_url(place_id: str) -> str:
    # m.place ë°©ë¬¸ì ë¦¬ë·° URL
    return f"https://m.place.naver.com/restaurant/{place_id}/review/visitor?entry=ple&reviewSort=recent"

def extract_place_id_from_url(url: str) -> str | None:
    # ì •ê·œì‹ì€ raw-stringìœ¼ë¡œ, ë‹¨ì¼ ë°±ìŠ¬ë˜ì‹œ ì‚¬ìš©
    m = re.search(r"/place/(\d+)", url)  # [13][17]
    return m.group(1) if m else None

def append_to_excel(path: str, row_dict: dict):
    # ê°„ë‹¨ ë³‘í•© ì €ì¥(íŒŒì¼ ì—†ìœ¼ë©´ ìƒì„±)
    df_new = pd.DataFrame([row_dict])
    if not os.path.exists(path):
        df_new.to_excel(path, index=False)
        print(f"ğŸ“Š ìƒˆ íŒŒì¼ ìƒì„±: {path}")
        return
    try:
        existing_df = pd.read_excel(path)
        combined_df = pd.concat([existing_df, df_new], ignore_index=True)
        combined_df.to_excel(path, index=False)
        print("ğŸ“Š ì—‘ì…€ ì¶”ê°€ ì™„ë£Œ")
    except Exception as e:
        # ë°±ì—… ê²½ë¡œ: openpyxl ì§ì ‘ append
        try:
            book = load_workbook(path)
            with pd.ExcelWriter(path, engine="openpyxl", mode="a", if_sheet_exists="overlay") as writer:
                writer.book = book
                writer.sheets = {ws.title: ws for ws in book.worksheets}
                startrow = writer.sheets["Sheet1"].max_row
                df_new.to_excel(writer, index=False, header=False, startrow=startrow)
            print("ğŸ“Š ì—‘ì…€ append(ë°±ì—…) ì™„ë£Œ")
        except Exception as ee:
            print(f"âŒ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨: {e} / ë°±ì—…ë„ ì‹¤íŒ¨: {ee}")

# ===== í•µì‹¬: ê²€ìƒ‰ URL ì§ì ‘ ì ‘ê·¼í•˜ì—¬ place_id ì¶”ì¶œ =====
def search_via_search_url_and_get_place_id(driver, name: str, wait: WebDriverWait, settle_sec: float = 1.0) -> str | None:
    """
    https://map.naver.com/p/search/{ì—…ì²´ëª…} ë¡œ ì§ì ‘ ì ‘ê·¼.
    ë‹¨ì¼ ê²°ê³¼ë¡œ í™•ì •ë˜ë©´ í˜„ì¬ URLì— /place/{id}ê°€ ë‚˜íƒ€ë‚¨ â†’ place_id ë°˜í™˜.
    ëª©ë¡ í™”ë©´ì´ë©´ ì²« ê²°ê³¼ í´ë¦­ í´ë°± ì‹œë„.
    """
    encoded = urllib.parse.quote(name, safe="")  # í•œê¸€/ê³µë°± ì•ˆì „ ì¸ì½”ë”© [9][12]
    url = f"https://map.naver.com/p/search/{encoded}"
    driver.get(url)
    time.sleep(settle_sec)

    # ë‹¨ì¼ ê²°ê³¼ ë¼ìš°íŒ… ê°ì§€: /place/{ìˆ«ì}ê°€ current_urlì— ë“±ì¥í•˜ëŠ”ì§€ í™•ì¸
    try:
        WebDriverWait(driver, 5).until(lambda d: re.search(r"/place/\d+", d.current_url) is not None)
    except Exception:
        pass

    current = driver.current_url
    pid = extract_place_id_from_url(current)
    if pid:
        print(f"âœ… ë‹¨ì¼ ê²°ê³¼ í™•ì • â†’ place_id: {pid} (from {current})")
        return pid

    # í´ë°±: ëª©ë¡ í™”ë©´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ê²°ê³¼ í´ë¦­ ì‹œë„
    try:
        anchors = driver.find_elements(By.CSS_SELECTOR, "a.place_bluelink")
        if not anchors:
            anchors = driver.find_elements(By.CSS_SELECTOR, "a.a_item_click, a.UEzoS")
        if anchors:
            anchors.click()  # ë¦¬ìŠ¤íŠ¸ ì¤‘ ì²« ê²°ê³¼ í´ë¦­ [1][2]
            WebDriverWait(driver, 8).until(lambda d: re.search(r"/place/\d+", d.current_url))
            current = driver.current_url
            pid = extract_place_id_from_url(current)
            if pid:
                print(f"âœ… í´ë°± ì„±ê³µ â†’ place_id: {pid} (from {current})")
                return pid
    except Exception as e:
        print(f"âš ï¸ í´ë°± ë‹¨ê³„ ì˜¤ë¥˜: {e}")

    print("âŒ place_id ì¶”ì¶œ ì‹¤íŒ¨(ê²€ìƒ‰ URL ê²½ë¡œ)")
    return None

# ===== ë©”ì¸ =====
def main():
    print("ğŸš€ ì‹œì‘")
    df = read_korean_csv(INPUT_PATH)
    print(f"ğŸ“‹ ëŒ€ìƒ {len(df)}ê±´")

    options = webdriver.ChromeOptions()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    driver = webdriver.Chrome(options=options)
    wait = WebDriverWait(driver, 15)

    success = 0
    fail = 0
    no = 1

    for idx, row in df.iterrows():
        name = str(row.get(NAME_COL, "")).strip()
        if not name:
            continue

        print(f"\n{'='*50}\nğŸ” [{idx+1}/{len(df)}] {name}")

        pid = search_via_search_url_and_get_place_id(driver, name, wait, settle_sec=2.0)
        if not pid:
            print(f"âŒ {name} â†’ place_id ì‹¤íŒ¨")
            fail += 1
            time.sleep(0.5)
            continue

        review_url = build_review_url(pid)
        append_to_excel(OUTPUT_PATH, {
            "no": no,
            "store_name": name,
            "store_url_naver": review_url
        })
        print(f"âœ… ì €ì¥: {review_url}")
        success += 1
        no += 1
        time.sleep(0.8)

    driver.quit()
    print(f"\nğŸ‰ ì™„ë£Œ: ì„±ê³µ {success}, ì‹¤íŒ¨ {fail}")
    print(f"ğŸ“„ ê²°ê³¼ íŒŒì¼: {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
