import json
import os
from collections import Counter
import pandas as pd

def analyze_top_cluster_distribution(personalized_dir):
    """
    ê° ìœ ì €ì˜ 1ë“± í´ëŸ¬ìŠ¤í„° ë¶„í¬ ë¶„ì„
    """
    top_cluster_ids = []
    user_cluster_data = []
    
    # ëª¨ë“  JSON íŒŒì¼ ì½ê¸°
    json_files = [f for f in os.listdir(personalized_dir) if f.endswith('.json')]
    
    print(f"ğŸ“‚ ì´ {len(json_files)}ê°œ íŒŒì¼ ë¶„ì„ ì¤‘...\n")
    
    for json_file in sorted(json_files):
        file_path = os.path.join(personalized_dir, json_file)
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        user_id = data['user_id']
        travel_style = data['travel_style']
        
        # hotzonesì˜ ì²« ë²ˆì§¸(1ë“±) í´ëŸ¬ìŠ¤í„°
        if len(data['hotzones']) > 0:
            top_cluster = data['hotzones'][0]
            cluster_id = top_cluster['cluster_id']
            cluster_score = top_cluster['cluster_user_score']
            
            top_cluster_ids.append(cluster_id)
            user_cluster_data.append({
                'user_id': user_id,
                'travel_style': travel_style,
                'top_cluster_id': cluster_id,
                'cluster_score': cluster_score
            })
    
    # ë¶„í¬ ê³„ì‚°
    cluster_counter = Counter(top_cluster_ids)
    
    print("="*70)
    print("ğŸ“Š 1ë“± í´ëŸ¬ìŠ¤í„° ë¶„í¬ (ì „ì²´)")
    print("="*70)
    
    for cluster_id, count in cluster_counter.most_common():
        percentage = (count / len(json_files)) * 100
        print(f"í´ëŸ¬ìŠ¤í„° {cluster_id}: {count}ëª… ({percentage:.1f}%)")
    
    # ì—¬í–‰ ìŠ¤íƒ€ì¼ë³„ ë¶„í¬
    print("\n" + "="*70)
    print("ğŸ¨ ì—¬í–‰ ìŠ¤íƒ€ì¼ë³„ 1ë“± í´ëŸ¬ìŠ¤í„° ë¶„í¬")
    print("="*70)
    
    df = pd.DataFrame(user_cluster_data)
    
    for style in df['travel_style'].unique():
        print(f"\nğŸ·ï¸ {style}:")
        style_df = df[df['travel_style'] == style]
        style_counter = Counter(style_df['top_cluster_id'])
        
        for cluster_id, count in style_counter.most_common(5):  # ìƒìœ„ 5ê°œë§Œ
            percentage = (count / len(style_df)) * 100
            print(f"  í´ëŸ¬ìŠ¤í„° {cluster_id}: {count}ëª… ({percentage:.1f}%)")
    
    # í†µê³„ ìš”ì•½
    print("\n" + "="*70)
    print("ğŸ“ˆ í†µê³„ ìš”ì•½")
    print("="*70)
    print(f"ì´ ìœ ì € ìˆ˜: {len(json_files)}ëª…")
    print(f"ìœ ë‹ˆí¬ 1ë“± í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(cluster_counter)}ê°œ")
    print(f"ê°€ì¥ ì¸ê¸°ìˆëŠ” í´ëŸ¬ìŠ¤í„°: {cluster_counter.most_common(1)[0][0]}ë²ˆ ({cluster_counter.most_common(1)[0][1]}ëª…)")
    
    # ìƒì„¸ í…Œì´ë¸” ì €ì¥
    output_csv = os.path.join(personalized_dir, "top_cluster_distribution.csv")
    df.to_csv(output_csv, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ ìƒì„¸ ë°ì´í„° ì €ì¥: {output_csv}")
    
    return df, cluster_counter


# ========================================
# ğŸš€ ì‹¤í–‰
# ========================================
if __name__ == "__main__":
    base_dir = r"C:\Users\changjin\workspace\lab\pln"
    personalized_dir = os.path.join(base_dir, "clustering", "personalized_hotzones")
    
    df, distribution = analyze_top_cluster_distribution(personalized_dir)